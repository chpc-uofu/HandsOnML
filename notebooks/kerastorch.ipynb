{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12cb4c0a-e099-446b-9097-6e31656f66e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple, List, Dict, Any\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Keras (Torch) as backend\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"   # IF NOT SPECIFIED, TensorFlow will be used as BACKEND\n",
    "import keras\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c4867-854a-458e-bed4-c18e4caaf354",
   "metadata": {},
   "source": [
    "# Logistic regression using Keras & PyTorch\n",
    "* <font color=\"teal\"><b>author: Wim R.M. Cardoen</b></font>\n",
    "* <font color=\"teal\"><b>e-mail: wcardoen [\\at] gmail.com</b></font>\n",
    "\n",
    "* For <font color=\"green\"><b>more advanced networks</b></font> most AI/deep learing practitioners:\n",
    "  - neither derive the underlying equations.\n",
    "  - nor implement these equations from scratch.\n",
    "* Implementing <font color=\"green\"><b>highly performant code</b></font>\n",
    "  for the general case is significantly more <font color=\"green\"><b>demanding and time-consuming</b></font>.<br>It requires:\n",
    "  - mastery of a <font color=\"red\"><b>compiled language</b></font> (e.g., `C++`)\n",
    "  - understanding of <font color=\"red\"><b>parallel computing</b></font> (multi-node, multi-GPU setups).\n",
    "  - a solid foundation in <font color=\"red\"><b>algorithms and numerical analysis</b></font>.\n",
    "* To address these kind of challenges, humanity adopted over time a\n",
    "  <a href=\"https://www.marxists.org/reference/archive/smith-adam/works/wealth-of-nations/book01/ch01.htm\"><b>division of labour</b></a>.   \n",
    "* Instead of building everything from scratch, practitioners rely on <font color=\"green\"><b>frameworks</b></font>.<br>The most commonly used frameworks are currently:\n",
    "  - <a href=\"https://pytorch.org/\"><b>PyTorch</b></a>\n",
    "  - <a href=\"https://www.tensorflow.org/\"><b>TensorFlow</b></a>\n",
    "  - <a href=\"https://docs.jax.dev/en/latest/\"><b>Jax</b></a>\n",
    "  - <a href=\"https://keras.io/\"><b>Keras</b></a>\n",
    "  \n",
    "Our goal is to implement the logistic regression model (<a href=\"./lecture1.ipynb\"><b>Lecture 1</b></a>) using Keras & PyTorch.\n",
    "\n",
    "We will proceed in two different ways:\n",
    "1. by using <font color=\"green\"><b>Keras</b></font> (PyTorch as backend) : more user-friendly \n",
    "2. by using <font color=\"green\"><b>PyTorch</b></font> as such: low-level but versatile.\n",
    "\n",
    "In <a href=\"./lecture2.ipynb\"><b>Lecture 2</b></a> we will use Keras but will also provide its lower level counter part (as addendum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aeac246-3cb3-4ca6-bed2-976bc3d82e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate the data set ...\n",
      "  X.shape:(500, 2)\n",
      "  y.shape:(500,)\n",
      "Splitting the data set (splitting ratio:0.3)\n",
      "  Training Data Set:\n",
      "    X_train.shape : (350, 2)\n",
      "    y_train.shape : (350,)\n",
      "  Test Data Set:\n",
      "    X_test.shape  : (150, 2)\n",
      "    y_test.shape  : (150,)\n"
     ]
    }
   ],
   "source": [
    "# Generate a data set\n",
    "X, y = make_moons(n_samples=500, noise=0.25, random_state=42)\n",
    "print(f\"Generate the data set ...\")\n",
    "print(f\"  X.shape:{X.shape}\")\n",
    "print(f\"  y.shape:{y.shape}\")\n",
    "\n",
    "# Split the data in training and a test set.\n",
    "test_ratio = 0.30\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_ratio, random_state=42)\n",
    "print(f\"Splitting the data set (splitting ratio:{test_ratio})\")\n",
    "print(f\"  Training Data Set:\")\n",
    "print(f\"    X_train.shape : {X_train.shape}\")\n",
    "print(f\"    y_train.shape : {y_train.shape}\")\n",
    "print(f\"  Test Data Set:\")\n",
    "print(f\"    X_test.shape  : {X_test.shape}\")\n",
    "print(f\"    y_test.shape  : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5963890e-8640-428e-b3f9-c4885cd489d5",
   "metadata": {},
   "source": [
    "# 1.Keras (with PyTorch backend)\n",
    "Phases:<br>\n",
    "- A. set up the model: specify the layers and units\n",
    "- B. `compile` the model: specify the optimizer, loss, metrics\n",
    "- C. `fit` the model: training\n",
    "- D. `evaluate` the model: testing\n",
    "- E. `predict`: use the model to predict outcomes for input samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bbf9fe-28ad-47b3-bebe-cbd3eb211a5e",
   "metadata": {},
   "source": [
    "### A.Set up the model\n",
    "consists mainly of:\n",
    "- providing the layout of the neural net (layers and #units/layer)\n",
    "- specifying the activation functions for each layer\n",
    "  \n",
    "`Sequential class`: groups a linear stack of layers into a Model (For more info on the API, see <a href=\"https://keras.io/api/models/sequential/\"><b>here</b></a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c9fe847-3467-425e-ae0c-31fe76d5deb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"LogisticRegression\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"LogisticRegression\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Info on the layers ...\n",
      "  Layer:'dense'\n",
      "{'name': 'dense', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 1, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n"
     ]
    }
   ],
   "source": [
    "# Setting up the model\n",
    "model1 =  keras.Sequential([\n",
    "                keras.layers.Input(shape=(2,)),                      # Input layer: input vector (2 features)\n",
    "                keras.layers.Dense(units=1, activation='sigmoid')],  # Output layer: 1 Class\n",
    "                name=\"LogisticRegression\")       \n",
    "print(model1.summary())\n",
    "\n",
    "# Info on kernel_regularization, etc.\n",
    "print(f\"Info on the layers ...\")\n",
    "for layer in model1.layers:\n",
    "    print(f\"  Layer:'{layer.name}'\")\n",
    "    print(layer.get_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c6d5b4-eba9-40ea-8ffd-233ab0fe1207",
   "metadata": {},
   "source": [
    "### B.Compile the model\n",
    "\n",
    "The `compile` method's task it to provide the model with:\n",
    "- an <font color=\"teal\"><b>optimization method/optimizer</b></font> (e.g. `SGD`, `RMSprop`,`Adam`, `AdamW`, $\\ldots$)<br>\n",
    "  (For more info on the optimizers, see <a href=\"https://keras.io/api/optimizers/\"><b>here</b></a>)\n",
    "- a <font color=\"teal\"><b>loss</b></font> function (e.g. `binary_crossentropy`, `categorical_crossentropy`, `mean_squared_error` , $\\ldots$)<br>\n",
    "  (For more info on the loss function, see <a href=\"https://keras.io/api/losses/\"><b>here</b></a>)\n",
    "- <font color=\"teal\"><b>metrics</b></font> (e.g. `accuracy` $\\ldots$)<br>\n",
    "  (For more info on the metrics, see <a href=\"https://keras.io/api/metrics/\"><b>here</a></a>)\n",
    "\n",
    "`compile`: (For more info on the method, see <a href=\"https://keras.io/api/models/model_training_apis/#compile-method\"><b>here</b></a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f8fd65-9f89-451e-a7d2-0a8e8ef41bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation models\n",
      "  Optimizer: <keras.src.backend.torch.optimizers.torch_sgd.SGD object at 0x760f90faa270>\n",
      "  Optimizer Config: {'name': 'SGD', 'learning_rate': 0.07500000298023224, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'momentum': 0.0, 'nesterov': False}\n",
      "  Loss Function: binary_crossentropy\n",
      "  Metrics: [<Mean name=loss>, <CompileMetrics name=compile_metrics>]\n"
     ]
    }
   ],
   "source": [
    "# Compilation of the model\n",
    "optimizer = SGD(learning_rate=0.075)\n",
    "model1.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(f\"Compilation models\")\n",
    "print(f\"  Optimizer: {model1.optimizer}\")\n",
    "print(f\"  Optimizer Config: {model1.optimizer.get_config()}\")\n",
    "print(f\"  Loss Function: {model1.loss}\")\n",
    "print(f\"  Metrics: {model1.metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad52b256-5d8f-49e0-926f-d543b6529c7d",
   "metadata": {},
   "source": [
    "### C.Train the model\n",
    "- The `fit` method is used to train the model.<br>\n",
    "  (For more info on the method, see <a href=\"https://keras.io/api/models/model_training_apis/#fit-method\"><b>here</b></a>)\n",
    "- This method has important arguments, e.g.:<br>\n",
    "  * `epochs`: number of passes through the **complete** data set.\n",
    "  * `batch_size`: number of samples used per gradient update. (Default: $[32]$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feac98c2-de9f-44a0-92ee-c44bae91927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model1.fit(X_train, y_train, epochs=1000, verbose=0)\n",
    "#print(history.history)\n",
    "loss = history.history['loss']\n",
    "accuracy=history.history['accuracy']\n",
    "it = np.arange(len(loss))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03202081-e0d0-46f2-8d61-33ebfb4af09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Loss of the training data\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(it,loss,\"-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad15a525-a289-4c80-9d1f-befd5e2932b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters at the end of the training\n",
      "  Layer   : dense\n",
      "  Weights : [ 1.2494235 -4.2733297]\n",
      "  Bias    : [0.40958008]\n"
     ]
    }
   ],
   "source": [
    "# Final weights and bias\n",
    "print(f\"Parameters at the end of the training\")\n",
    "for layer in model1.layers:\n",
    "    weights, biases = layer.get_weights()\n",
    "    print(f\"  Layer   : {layer.name}\")\n",
    "    print(f\"  Weights : {np.ravel(weights)}\")\n",
    "    print(f\"  Bias    : {biases}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996cd386-c412-4b3a-b8a5-54b2c421fdd0",
   "metadata": {},
   "source": [
    "### D.Test the model\n",
    "\n",
    "The `evaluate` method returns the `loss` value & `metrics` values for the model in test mode.<br>\n",
    "(For more info on the method, see <a href=\"https://keras.io/api/models/model_training_apis/#evaluate-method\"><b>here</b></a>)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac992dde-fc44-4884-8e59-97b9ee777ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8600 - loss: 0.3035\n",
      "Evaluation of the test set\n",
      "  Accuracy :   0.8600\n",
      "  Loss     :   0.3035\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model1.evaluate(X_test, y_test)\n",
    "print(f\"Evaluation of the test set\")\n",
    "print(f\"  Accuracy : {test_accuracy:8.4f}\")\n",
    "print(f\"  Loss     : {test_loss:8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a68544-7138-47f4-8d3f-a8811575b554",
   "metadata": {},
   "source": [
    "### E.Predict outcomes\n",
    "\n",
    "The `predict` method generates output predictions for the input samples.<br>\n",
    "(For more info on the method, see <a href=\"https://keras.io/api/models/model_training_apis/#predict-method\"><b>here</b></a>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1d650dd-5598-45dd-b4b7-afbe7a9339a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a sample of X values ...\n",
      "  X.shape:(100, 2)\n",
      "  #same  :85\n"
     ]
    }
   ],
   "source": [
    "# Generate a data set\n",
    "print(f\"Generate a sample of X values ...\")\n",
    "X_sample, y_sample = make_moons(n_samples=100, noise=0.25, random_state=12)\n",
    "print(f\"  X.shape:{X_sample.shape}\")\n",
    "y_pred = model1.predict(X_sample,verbose=0)\n",
    "y_pred = np.where(y_pred>0.5,1,0).squeeze()\n",
    "print(f\"  #same  :{np.sum(y_pred ==y_sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3a4da2-c8cb-457d-b510-2d557769b175",
   "metadata": {},
   "source": [
    "# 2.PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2ba59b-d299-49d1-9f0e-ee546657913c",
   "metadata": {},
   "source": [
    "### Data conversion/Data Loaders\n",
    "* We have 2 PyTorch data classes (to be discussed later):\n",
    "  + data.Dataset : to load/create data in a class<br>\n",
    "    requires: \\_\\_init\\_\\_(), \\_\\_len\\_\\_(), \\_\\_getitem\\_\\_()\n",
    "  + data.DataLoader:: to load data in batches\n",
    "* For the time being (conversion to PyTorch Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "138b0abe-2f46-4349-a7ab-7d530a673784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the PyTorch Tensors from the NumPy Data\n",
    "# Note: default torch.float32\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1,1)  # 2D \n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1,1)    # 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "593a282d-7154-4cfc-8af1-021cd7e8f626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy data::\n",
      "  X_train: (350, 2)\n",
      "[[ 1.3002999  -0.53762795]\n",
      " [-0.8817249   0.18799726]]\n",
      "  y_train: (350,)\n",
      "[1 0]\n",
      "\n",
      "PyTorch data::\n",
      "  X_train_tensor: torch.Size([350, 2])\n",
      "tensor([[ 1.3003, -0.5376],\n",
      "        [-0.8817,  0.1880]])\n",
      "  y_train_tensor: torch.Size([350, 1])\n",
      "tensor([[1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "# Check Conversion from NumPy to PyTorch Tensor\n",
    "START, END= 0, 2\n",
    "print(f\"NumPy data::\")\n",
    "print(f\"  X_train: {X_train.shape}\\n{X_train[START:END]}\")\n",
    "print(f\"  y_train: {y_train.shape}\\n{y_train[START:END]}\")\n",
    "print(f\"\\nPyTorch data::\")\n",
    "print(f\"  X_train_tensor: {X_train_tensor.shape}\\n{X_train_tensor[START:END]}\")\n",
    "print(f\"  y_train_tensor: {y_train_tensor.shape}\\n{y_train_tensor[START:END]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc197963-abb7-4e21-a87a-1313a5c318a6",
   "metadata": {},
   "source": [
    "### A.Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "872f0b4c-90c6-42bd-8999-39f4c3bdb1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic Regression module using PyTorch\n",
    "class LogisticRegressionModel2(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs):\n",
    "\n",
    "        # The class inherits from the class nn.Module\n",
    "        super(LogisticRegressionModel2,self).__init__()\n",
    "\n",
    "        # Define a Single LAYER object which connects \n",
    "        #     the input with 1 single output \n",
    "        self.linear = nn.Linear(num_inputs, 1)\n",
    "\n",
    "        # Create the ACTIVATION (object) for the Single Layer\n",
    "        self.act_fn = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Applies the forward propagation\n",
    "        z = self.linear(x)\n",
    "        a = self.act_fn(z)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce21371-e24d-4ad9-b175-7e5877c0ec59",
   "metadata": {},
   "source": [
    "<font color=\"red\"><b>Note</b></font>:\n",
    "* `nn.Linear(in_features, out_features)`:\n",
    "   <a href=\"https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html\"><b>affine transformation</b></a>\n",
    "* `nn.Sigmoid()`: <a href=\"https://docs.pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid\"><b>sigmoid function</b></a>\n",
    "* $\\ldots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e33762e7-caa2-41c5-85bb-d3af7dc7e35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Logistic Model:LogisticRegressionModel2(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (act_fn): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model2 = LogisticRegressionModel2(num_inputs=2)\n",
    "print(f\"  Logistic Model:{model2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3f833ee-138a-4c71-abe3-82b1e5aec1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:linear.weight        -> param:torch.Size([1, 2])\n",
      "tensor([[ 0.5456, -0.1317]])\n",
      "\n",
      "Name:linear.bias          -> param:torch.Size([1])\n",
      "tensor([0.0167])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In PyTorch, you can use either the parameters() function\n",
    "# or the names_parameters() function\n",
    "for name, param in model2.named_parameters():\n",
    "    print(f\"Name:{name:20s} -> param:{param.shape}\")\n",
    "    print(f\"{param.data}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2428beba-5dea-48ae-9d5c-ed0ab1401400",
   "metadata": {},
   "source": [
    "### B.Compiling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e37927-445f-4aac-9c32-ab9145f1cbfb",
   "metadata": {},
   "source": [
    "#### B1.Loss/Objective function\n",
    "* In order to find the <font color=\"green\"><b>optimal parameters</b></font> for the weights and bias, we need\n",
    "  to have an <font color=\"green\"><b>objective function</b></font> (a.k.a Loss function)\n",
    "* There are several options:\n",
    "  + <a href=\"https://docs.pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#bceloss\"><b>nn.BCELoss()</b></a>:<br>\n",
    "  **B**inary **C**ross **E**ntropy => inputs need to be $[0,1]$<br>\n",
    "  $\\begin{eqnarray}\n",
    "  \\mathcal{L}^{(i)} & = & -\\bigg [ y_i \\log(a_i) + (1-y_i)\\log(1-a_i) \\bigg ]\n",
    "  \\end{eqnarray}$\n",
    "  + <a href=\"https://docs.pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss\"><b>nn.BCEWithLogitLoss()</b></a>:<br> Numerically more stable because of the combination of sigmoid and loss function at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a17cb990-6c6d-4b2d-8726-f5e8ef3623d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates an instance of the Binary Cross Entropy Criterion\n",
    "loss_fn2 = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24295432-ce38-4ebd-9557-3b0ff81d049a",
   "metadata": {},
   "source": [
    "#### B2.Optimization\n",
    "* There are several methods to <font color=\"green\"><b>optimize</b></font> the Loss function/Objective function.<br>\n",
    "  - In this example we will use the <a href=\"https://docs.pytorch.org/docs/stable/generated/torch.optim.SGD.html#sgd\"><b>Stochastic Gradient Descent (SGD)</b></a> method<br>\n",
    "    (<a href=\"https://docs.pytorch.org/docs/stable/optim.html\"><b>torch.optim module</b></a>).\n",
    "  - Later on, we will describe more powerful <font color=\"green\"><b>optimization algorithms</b></font> (`Adam`, `AdamW`, ...).\n",
    "* Useful methods:\n",
    "  + step(): method update parameters\n",
    "  + zero_grad() : sets the gradients of ALL optimized parameters to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "00445b61-2484-4c71-8f76-d8c54758efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim2 = optim.SGD(model2.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6747b-5400-4995-90e1-718fc0dcd6e2",
   "metadata": {},
   "source": [
    "### C.Train the model\n",
    "* Goal: Obtain the optimized parameters i.e. <font color=\"green\"><b>weight matrix</b></font> and <font color=\"green\"><b>bias</b></font>\n",
    "* If the data set is **small**, then we will use **all** the training data at **once**.\n",
    "* Terminology:\n",
    "  - **One** complete iteration over **all** training data: <font color=\"green\"><b>epoch</b></font>\n",
    "  - For **larger** training data sets, each <font color=\"green\"><b>epoch</b></font> is split into <font color=\"green\"><b>batches</b></font>.<br>\n",
    "    * The gradient and the parameters are <font color=\"blue\"><b>updated</b></font> after every batch (points are selected <font color=\"blue\"><b>randomly</b></font>):<br>\n",
    "      <font color=\"green\"><b>stochastic gradient descent (SGD)</b></font>\n",
    "    * The batch size is a <font color=\"green\"><b>hyperparameter</b></font>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f75a1e4-75c4-47e7-9715-9f03657a6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train_tensor, y_train_tensor, model, loss_fn, \n",
    "                optim, num_epochs=100000 , delta_print=10000):\n",
    "    \"\"\"\"\n",
    "    Function which trains the model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set model to train mode\n",
    "    # Strictly not necessary for our case \n",
    "    model.train()\n",
    "\n",
    "    # Loop over the epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # PART A: FORWARD PROPAGATION ( => )\n",
    "        # Step 1: Generate the output (activation of the linear layer)\n",
    "        output = model(X_train_tensor)\n",
    "\n",
    "        # Step 2: Use the activation of the last layer & the labels\n",
    "        #         to calculate the loss.\n",
    "        loss = loss_fn(output, y_train_tensor)\n",
    "\n",
    "        # Step B: BACK PROPAGATION ( <= )\n",
    "        # Step 3: Calculate the gradients of the parameters\n",
    "        optim.zero_grad()   # Init. the gradients to ZERO!!\n",
    "        loss.backward()     # Calc. grad. of param.\n",
    "\n",
    "        # Step 4: Adjust the parameters \n",
    "        optim.step()\n",
    "\n",
    "        if (epoch+1)%delta_print == 0 or epoch==0:\n",
    "           print(f\"  Epoch {epoch+1}/{num_epochs}  Loss:{loss.item():.6f}\")\n",
    "                \n",
    "    return loss.item()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4deac211-6416-43c3-a296-ff7066de3eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1/100000  Loss:0.301552\n",
      "  Epoch 10000/100000  Loss:0.301552\n",
      "  Epoch 20000/100000  Loss:0.301552\n",
      "  Epoch 30000/100000  Loss:0.301552\n",
      "  Epoch 40000/100000  Loss:0.301552\n",
      "  Epoch 50000/100000  Loss:0.301552\n",
      "  Epoch 60000/100000  Loss:0.301552\n",
      "  Epoch 70000/100000  Loss:0.301552\n",
      "  Epoch 80000/100000  Loss:0.301552\n",
      "  Epoch 90000/100000  Loss:0.301552\n",
      "  Epoch 100000/100000  Loss:0.301552\n",
      "Loss in the last step:0.301552\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "final_loss2 = train_model(X_train_tensor, y_train_tensor, model2, loss_fn2, optim2)\n",
    "print(f\"Loss in the last step:{final_loss2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a76000b-3ef8-4003-9358-5dd881c31f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METHOD 1::\n",
      "Weights::\n",
      "Parameter containing:\n",
      "tensor([[ 1.2507, -4.2648]], requires_grad=True)\n",
      "\n",
      "Bias   ::\n",
      "Parameter containing:\n",
      "tensor([0.4057], requires_grad=True)\n",
      "\n",
      "METHOD 2::\n",
      "linear.weight -> torch.Size([1, 2])\n",
      "  tensor([[ 1.2507, -4.2648]])\n",
      "linear.bias -> torch.Size([1])\n",
      "  tensor([0.4057])\n"
     ]
    }
   ],
   "source": [
    "# HOW TO Check the final parameters\n",
    "#   Method 1:\n",
    "print(f\"METHOD 1::\")\n",
    "print(f\"Weights::\\n{model2.linear.weight}\\n\")\n",
    "print(f\"Bias   ::\\n{model2.linear.bias}\")\n",
    "\n",
    "print(f\"\\nMETHOD 2::\")\n",
    "for name, param in model2.state_dict().items():\n",
    "    print(f\"{name} -> {param.shape}\")\n",
    "    print(f\"  {param.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b6fc7-23f5-4431-9e98-56386149effd",
   "metadata": {},
   "source": [
    "#### Save/load the model to & from disk\n",
    "* To <font color=\"green\"><b>save</b></font> an object to disk, use <a href=\"https://docs.pytorch.org/docs/stable/generated/torch.save.html#torch-save\"><b>torch.save()</b></a>\n",
    "* To <font color=\"green\"><b>load</b></font> an object from disk, use <a href=\"https://docs.pytorch.org/docs/stable/generated/torch.load.html#torch-load\"><b>torch.load()</b></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7cb9f8f6-0fef-4da3-8159-fed99f5727eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename='linreg2.pth'\n",
    "torch.save(model2.state_dict(), filename)\n",
    "\n",
    "newmodel = LogisticRegressionModel2(num_inputs=2)\n",
    "state = torch.load(filename, map_location=\"cpu\")\n",
    "newmodel.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e11d92-5ea9-487a-b9bd-9c8d4278fa50",
   "metadata": {},
   "source": [
    "<font color=\"red\"><b>Important Notes:</b><font>\n",
    "* The line `output = model(X_train_tensor)` calls the **forward** method.<br>\n",
    "  How does this work?\n",
    "  - `model(X_train_tensor)` invokes the `__call__` method<br> of the base class i.e. $\\texttt{nn.Module}$\n",
    "  - The `__call__` method does 2 things:\n",
    "    + Handles hooks (e.g. for debugging)\n",
    "    + Calls the `forward` method.\n",
    "* `optim.zero_grad()`: forces to set the gradient vector to zero (accumulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8a0f91-2301-4012-a13d-dfc560be46e2",
   "metadata": {},
   "source": [
    "### D.Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa9c9247-bcb5-4291-86b3-9b6fb0f5d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(X_tensor, y_tensor, model):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        res_tensor = model(X_tensor)\n",
    "        ypred_tensor =(res_tensor>0.5).float()\n",
    "    return ypred_tensor    \n",
    "\n",
    "def get_accuracy(y_pred, y):\n",
    "    num_ok = float((y_pred == y).sum())\n",
    "    return (num_ok / y_pred.shape[0]) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38f80995-21d5-4917-a824-0194a47ee851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 84.2857\n",
      "Accuracy test: 86.0000\n"
     ]
    }
   ],
   "source": [
    "y_trainpred_tensor = test_model(X_train_tensor, y_train_tensor, model2)\n",
    "acc_train = get_accuracy(y_trainpred_tensor, y_train_tensor)\n",
    "print(f\"Accuracy train:{acc_train:8.4f}\")\n",
    "\n",
    "y_testpred_tensor = test_model(X_test_tensor, y_test_tensor, model2)\n",
    "acc_test = get_accuracy(y_testpred_tensor, y_test_tensor)\n",
    "print(f\"Accuracy test:{acc_test:8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba7f7f9-cc94-40d5-8716-1a078bd98a8d",
   "metadata": {},
   "source": [
    "### Alternative implementation within PyTorch (numerical stability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13365877-aa9a-4cb1-9ae2-f449f2e530fe",
   "metadata": {},
   "source": [
    "In the previous section, we implemented the \n",
    "* <font color=\"green\"><b>activation function</b></font> $a_i$, i.e.<br>\n",
    "  $\\begin{eqnarray}\n",
    "     a_i & = & \\sigma(z_i)\\\\\n",
    "         & = & \\frac{1}{1+e^{-z_i}} \\\\\n",
    "  \\end{eqnarray}$\n",
    "* loss function $\\mathcal{L}^{(i)}$, i.e.<br>\n",
    "  $\\begin{eqnarray}\n",
    "       \\mathcal{L}^{(i)} & = & - \\bigg [ y_i \\log(a_i) + (1-y_i)\\log(1-a_i) \\bigg ] \n",
    "  \\end{eqnarray}$<br>\n",
    "separately.\n",
    "\n",
    "To render the <font color=\"green\"><b>optimization numerically more stable</b></font> the <font color=\"green\"><b>activation and the loss function</b></font> can be combined into **one** function.<br>\n",
    "The corresponding loss function bears the name <a href=\"https://docs.pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss\"><b>BCEWithLogitsLoss</b></a>\n",
    "and is given by:\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "  \\mathcal{L}^{(i)} & = & -\\bigg [ y_i \\log(a_i) + (1-y_i)\\log(1-a_i) \\bigg ]\\\\ \n",
    "                    & = & z_i(1-y_i) + \\log(1+e^{-z_i}) \\\\\n",
    "\\end{eqnarray}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6546feea-cd34-46a6-8b13-801452734d44",
   "metadata": {},
   "source": [
    "#### **Exercise 1**:\n",
    "* Implement the `class LogisticRegressionModelEx(nn.Module)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9695a53a-2235-4737-9d00-96b908d4991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic Regression module using PyTorch \n",
    "class LogisticRegressionModelEx(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs):\n",
    "\n",
    "        # The class inherits from the class nn.Module\n",
    "        super(LogisticRegressionModelEx,self).__init__()\n",
    "\n",
    "        # <--- YOUR CODE\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Applies the forward propagation\n",
    "        # <--- YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7427e650-c454-4a32-9e11-bd846b0a57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/kerastorch/sol_ex1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d025b52c-ef20-474f-8d78-924764afaee2",
   "metadata": {},
   "source": [
    "Check the model <font color=\"blue\"><b>(ante optimization)</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0eaa0a-6a45-48e3-9e78-47028c2f58d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEx = LogisticRegressionModelEx(num_inputs=2)\n",
    "print(f\"  Logistic Model:{modelEx}\")\n",
    "\n",
    "for name, param in modelEx.named_parameters():\n",
    "    print(f\"Name:{name:20s} -> param:{param.shape}\")\n",
    "    print(f\"{param.data}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0477716-cae5-4436-bb13-26bfa14d63f2",
   "metadata": {},
   "source": [
    "#### **Exercise 2**:\n",
    "* Implement the `loss_fnEx` using BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ea3a8-0d0f-4ccd-8a35-695ba436daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here comes your code to define the BCEWithLogitsLoss\n",
    "loss_fnEx = # <--- Here comes your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a9373f-328d-4fa1-9f06-9d645ceb0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/kerastorch/sol_ex2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f7506d-ffd3-4f42-9e5c-d61dee98da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimEx = optim.SGD(modelEx.parameters(), lr=0.005)\n",
    "final_lossEx = train_model(X_train_tensor, y_train_tensor, modelEx, loss_fnEx, optimEx)\n",
    "print(f\"Loss in the last step:{final_lossEx:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d09f515-1065-4855-b232-b7948dedddf1",
   "metadata": {},
   "source": [
    "Check the model <font color=\"blue\"><b>(post optimization)</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ae834-2ca9-47b8-b33b-eb7effda5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in modelEx.named_parameters():\n",
    "    print(f\"Name:{name:20s} -> param:{param.shape}\")\n",
    "    print(f\"{param.data}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
